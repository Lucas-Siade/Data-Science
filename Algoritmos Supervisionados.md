# üí° Algoritmos Supervisionados

Os algoritmos supervisionados utilizam conjuntos de dados rotulados para treinar modelos que fazem previs√µes ou classifica√ß√µes com base em exemplos anteriores. Esse tipo de algoritmo utiliza os valores passados da vari√°vel alvo para aprender quais devem ser seus resultados de sa√≠da, ajustando-se at√© que o erro tenha sido suficientemente minimizado.

## üìè Regress√£o Linear

### ‚öôÔ∏è Principais Caracter√≠sticas
A Regress√£o Linear √© um algoritmo que busca encontrar uma reta que melhor se ajusta aos dados, descrevendo a rela√ß√£o entre uma ou mais vari√°veis independentes e uma vari√°vel dependente. A Regress√£o Linear √© amplamente aplicada em problemas de previs√£o de valores cont√≠nuos, onde o objetivo √© estimar o resultado de uma vari√°vel com base em valores conhecidos das outras vari√°veis.

### ‚úÖ Vantagens
* **F√°cil de Implementar e Interpretar:** O modelo √© simples de entender e pode ser facilmente descrito com par√¢metros matem√°ticos.

* **Pouco Custo Computacional:** O treinamento √© r√°pido e ideal para conjuntos de dados pequenos e m√©dios.

* **Coeficientes Interpret√°veis:** Os pesos indicam claramente o impacto de cada vari√°vel, o que facilita an√°lises de neg√≥cio e decis√µes.

### ‚ùå Desvantagens
* **Limita√ß√£o com Rela√ß√µes N√£o Lineares:** Se a rela√ß√£o entre as vari√°veis for curva, circular ou qualquer padr√£o n√£o-reto, a Regress√£o Linear n√£o conseguir√° representar bem.

* **Vulner√°vel a Outliers:** Valores extremos podem distorcer muito o modelo final, gerando previs√µes erradas.

* **N√£o √© ideal para Classifica√ß√£o:** Mesmo que seja poss√≠vel, a Regress√£o Linear n√£o √© recomend√°vel para classificar.

### üéØ Principais Aplica√ß√µes
* **Previs√£o de Valores**
* **Estimatica de Pre√ßos**
* **Proje√ß√£o de Lucros e Despesas**
* **An√°lise de Tend√™ncias**

<br>

## üî¢ Regress√£o Log√≠stica

### ‚öôÔ∏è Principais Caracter√≠sticas
A Regress√£o Log√≠stica, apesar do nome, √© um modelo utilizado para Classifica√ß√£o, e n√£o para Regress√£o. Ela prev√™ a probabilidade de um exemplo pertencer a uma determinada classe, geralmente em problemas de classifica√ß√£o bin√°ria. Sua principal caracter√≠stica √© a fun√ß√£o sigmoide, que transforma a sa√≠da em um valor entre 0 e 1, tornando poss√≠vel a interpreta√ß√£o como uma probabilidade.

### ‚úÖ Vantagens
* **Efici√™ncia computacional:** Requer menos poder computacional em compara√ß√£o com redes neurais ou algoritmos mais complexos.

* **Generaliza√ß√£o:** Funciona bem quando h√° uma rela√ß√£o linear entre as vari√°veis independentes e a probabilidade do evento.

* **Probabilidades de sa√≠da:** Fornece a probabilidade de pertencimento a uma classe.

### ‚ùå Desvantagens
* **N√£o funciona bem com dados n√£o lineares:** Se os dados n√£o forem linearmente separ√°veis, o modelo ter√° um desempenho insatisfat√≥rio.

* **Sens√≠vel a Outliers:** Outliers podem impactar os coeficientes e reduzir a precis√£o do modelo.

* **Requer melhor prepara√ß√£o dos dados:** Pode exigir transforma√ß√µes e normaliza√ß√µes para melhor desempenho.

### üéØ Principais Aplica√ß√µes
* **Detec√ß√£o de Fraudes**
* **Diagn√≥stico de Doen√ßas**
* **An√°lise de Clientes**

<br>

## üìç K-Nearest Neighbor (KNN)

### ‚öôÔ∏è Principais Caracter√≠sticas
O **K-Nearest Neighbor (KNN)** √© um algoritmo n√£o param√©trico, ou seja, n√£o tenta ajustar alguma fun√ß√£o matem√°tica aos dados. Suas previs√µes s√£o baseadas na dist√¢ncia entre os pontos do conjunto de dados, atribuindo o resultado com base nos K exemplos mais pr√≥ximos da amostra de teste.  O algoritmo pode ser aplicado tanto para **Regress√£o** quanto para **Classifica√ß√£o**, embora seja mais comumente utilizado em tarefas de classifica√ß√£o.

### ‚úÖ Vantagens
* **F√°cil de Implementar:** √â um algoritmo intuitivo, com poucos par√¢metros e simples de entender.

* **Dispensa Fase de Treinamento:** Armazena diretamente os dados de treino, o que reduz o tempo de prepara√ß√£o.

* **Lida bem com M√∫ltiplas Classes:** Apresenta bom desempenho em problemas de classifica√ß√£o com mais de duas categorias.

* **Eficiente com Dados bem separados:** Funciona muito bem quando as classes est√£o nitidamente separadas.

### ‚ùå Desvantagens
* **Alto Custo Computacional:** Exige o c√°lculo da dist√¢ncia entre a amostra de teste e todos os pontos do conjunto de treino.

* **Sens√≠vel a Ru√≠dos e Outliers:** Dados fora do padr√£o podem distorcer as previs√µes e afetar negativamente a acur√°cia.

* **Escolha do K Ideal √© crucial** Valores muito pequenos ou muito altos de K podem prejudicar o desempenho.

### üéØ Principais Aplica√ß√µes
* **Detec√ß√£o de Anomalias**
* **Recomenda√ß√£o de Produtos**
* **Classifica√ß√£o de Doen√ßas**
* **Reconhecimento de Imagens**

<br>

## üå≤ Random Forest

### ‚öôÔ∏è Principais Caracter√≠sticas
A **Random Forest** √© um algoritmo de aprendizado baseado em um conjunto de √°rvores de decis√£o. Ele utiliza a t√©cnica de Bagging (Bootstrap Aggregating) para criar m√∫ltiplos subconjuntos aleat√≥rios dos dados de treinamento. Cada uma dessas √°rvores √© treinada com uma amostra diferente dos dados, selecionando aleatoriamente um subconjunto de vari√°veis.

### ‚úÖ Vantagens
* **Alta Precis√£o:** A combina√ß√£o de subconjuntos diferentes de dados desenvolve um modelo mais est√°vel.

* **Seguro contra Overfitting:** O modelo reduz o risco de Overfitting por utilizar m√∫ltiplas √°rvores e fazer uma "vota√ß√£o" dos resultados.

* **Lida com dados faltantes:** O modelo pode estimar os valores ausentes utilizando a m√©dia ponderada das observa√ß√µes ou utilizar √°rvores de decis√£o para preencher lacunas.

* **Indica a import√¢ncia das vari√°veis usadas na predi√ß√£o:** Consegue avaliar o impacto de cada vari√°vel e atribuir um peso de import√¢ncia.

### ‚ùå Desvantagens
* **Dificuldade de interpretar os resultados:** A decis√£o final vem da jun√ß√£o de muitas √°rvores.

* **Consome mais mem√≥ria:** O modelo precisa armazenar m√∫ltiplas √°rvores de decis√£o.

* **N√£o funciona bem com dados lineares:** Para problemas lineares, o modelo pode ser um exagero e at√© gerar previs√µes menos eficientes.

### üéØ Principais Aplica√ß√µes
* **Rela√ß√µes Banc√°rias**
* **Diagn√≥stico M√©dico**
* **Previs√£o no Mercado Financeiro**

<br>

## ‚ö° Support Vector Machine (SVM)

### ‚öôÔ∏è Principais Caracter√≠sticas
O **Support Vector Machine** √© um algoritmo que pode ser aplicado tanto para **Regress√£o** quanto para **Classifica√ß√£o**. O seu principal objetivo √© encontrar o melhor hiperplano que separa os dados, maximizando a dist√¢ncia entre os grupos diferentes em um espa√ßo N-dimensional.

### ‚úÖ Vantagens
* **Eficiente em espa√ßos de alta dimensionalidade:** O SVM mant√©m bom desempenho mesmo quando o conjunto de dados possui diversas *features*.

* **Eficiente com poucos dados:** O SVM foca apenas no pontos mais relevantes - chamados de **vetores de suporte** - para definir a fronteira de decis√£o.

* **Vers√°til:** Diferentes fun√ß√µes de Kernel podem ser aplicadas de acordo com o problema, permitindo que se adapte tanto a dados linearmente separ√°veis quanto a rela√ß√µes complexas.

### ‚ùå Desvantagens
* **N√£o √© t√£o escal√°vel:** O treinamento do modelo se torna cada vez mais dif√≠cil √† medida que o n√∫mero de amostras aumenta.

* **Sens√≠vel √† escolha do Kernel:** Uma configura√ß√£o inadequada do Kernel pode comprometer a capacidade de generaliza√ß√£o do modelo.

* **Dif√≠cil de interpretar Kernels n√£o lineares:** Quando utiliza fun√ß√µes complexas, como RBF ou Polinomial, o modelo se torna mais dif√≠cil de interpretar e entender como as decis√µes s√£o tomadas.

* **N√£o fornece probabilidade:** Por padr√£o, o modelo n√£o calcula a probabilidade das previs√µes apenas realiza uma classifica√ß√£o direta.

### üéØ Principais Aplica√ß√µes
* **Classifica√ß√£o de Texto**
* **Bioinform√°tica**
* **Classifica√ß√£o de Imagens**

üîó Refer√™ncias
