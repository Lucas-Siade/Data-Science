# üí° Algoritmos Supervisionados

Os algoritmos supervisionados utilizam conjuntos de dados rotulados para treinar modelos que fazem previs√µes ou classifica√ß√µes com base em exemplos anteriores. Esse tipo de algoritmo utiliza os valores passados da vari√°vel alvo para aprender quais devem ser seus resultados de sa√≠da, ajustando-se at√© que o erro tenha sido suficientemente minimizado.

## üìè Regress√£o Linear

### ‚öôÔ∏è Principais Caracter√≠sticas
A Regress√£o Linear √© um algoritmo que busca encontrar uma reta que melhor se ajusta aos dados, descrevendo a rela√ß√£o entre uma ou mais vari√°veis independentes e uma vari√°vel dependente. A Regress√£o Linear √© amplamente aplicada em problemas de previs√£o de valores cont√≠nuos, onde o objetivo √© estimar o resultado de uma vari√°vel com base em valores conhecidos das outras vari√°veis.

### ‚úÖ Vantagens
* **F√°cil de Implementar e Interpretar:** O modelo √© simples de entender e pode ser facilmente descrito com par√¢metros matem√°ticos.

* **Pouco Custo Computacional:** O treinamento √© r√°pido e ideal para conjuntos de dados pequenos e m√©dios.

* **Coeficientes Interpret√°veis:** Os pesos indicam claramente o impacto de cada vari√°vel, o que facilita an√°lises de neg√≥cio e decis√µes.

### ‚ùå Desvantagens
* **Limita√ß√£o com Rela√ß√µes N√£o Lineares:** Se a rela√ß√£o entre as vari√°veis for curva, circular ou qualquer padr√£o n√£o-reto, a Regress√£o Linear n√£o conseguir√° representar bem.

* **Vulner√°vel a Outliers:** Valores extremos podem distorcer muito o modelo final, gerando previs√µes erradas.

* **N√£o √© ideal para Classifica√ß√£o:** Mesmo que seja poss√≠vel, a Regress√£o Linear n√£o √© recomend√°vel para classificar.

### üéØ Principais Aplica√ß√µes
* **Previs√£o de Valores**
* **Estimatica de Pre√ßos**
* **Proje√ß√£o de Lucros e Despesas**
* **An√°lise de Tend√™ncias**

<br>

## üî¢ Regress√£o Log√≠stica

### ‚öôÔ∏è Principais Caracter√≠sticas
A Regress√£o Log√≠stica, apesar do nome, √© um modelo utilizado para Classifica√ß√£o, e n√£o para Regress√£o. Ela prev√™ a probabilidade de um exemplo pertencer a uma determinada classe, geralmente em problemas de classifica√ß√£o bin√°ria. Sua principal caracter√≠stica √© a fun√ß√£o sigmoide, que transforma a sa√≠da em um valor entre 0 e 1, tornando poss√≠vel a interpreta√ß√£o como uma probabilidade.

### ‚úÖ Vantagens
* **Efici√™ncia computacional:** Requer menos poder computacional em compara√ß√£o com redes neurais ou algoritmos mais complexos.

* **Generaliza√ß√£o:** Funciona bem quando h√° uma rela√ß√£o linear entre as vari√°veis independentes e a probabilidade do evento.

* **Probabilidades de sa√≠da:** Fornece a probabilidade de pertencimento a uma classe.

### ‚ùå Desvantagens
* **N√£o funciona bem com dados n√£o lineares:** Se os dados n√£o forem linearmente separ√°veis, o modelo ter√° um desempenho insatisfat√≥rio.

* **Sens√≠vel a Outliers:** Outliers podem impactar os coeficientes e reduzir a precis√£o do modelo.

* **Requer melhor prepara√ß√£o dos dados:** Pode exigir transforma√ß√µes e normaliza√ß√µes para melhor desempenho.

### üéØ Principais Aplica√ß√µes
* **Detec√ß√£o de Fraudes**
* **Diagn√≥stico de Doen√ßas**
* **An√°lise de Clientes**

<br>

## üìç K-Nearest Neighbor (KNN)

### ‚öôÔ∏è Principais Caracter√≠sticas
O **K-Nearest Neighbor (KNN)** √© um algoritmo n√£o param√©trico, ou seja, n√£o tenta ajustar alguma fun√ß√£o matem√°tica aos dados. Suas previs√µes s√£o baseadas na dist√¢ncia entre os pontos do conjunto de dados, atribuindo o resultado com base nos K exemplos mais pr√≥ximos da amostra de teste.  O algoritmo pode ser aplicado tanto para **Regress√£o** quanto para **Classifica√ß√£o**, embora seja mais comumente utilizado em tarefas de classifica√ß√£o.

### ‚úÖ Vantagens
* **F√°cil de Implementar:** √â um algoritmo intuitivo, com poucos par√¢metros e simples de entender.

* **Dispensa Fase de Treinamento:** Armazena diretamente os dados de treino, o que reduz o tempo de prepara√ß√£o.

* **Lida bem com M√∫ltiplas Classes:** Apresenta bom desempenho em problemas de classifica√ß√£o com mais de duas categorias.

* **Eficiente com Dados bem separados:** Funciona muito bem quando as classes est√£o nitidamente separadas.

### ‚ùå Desvantagens
* **Alto Custo Computacional:** Exige o c√°lculo da dist√¢ncia entre a amostra de teste e todos os pontos do conjunto de treino.

* **Sens√≠vel a Ru√≠dos e Outliers:** Dados fora do padr√£o podem distorcer as previs√µes e afetar negativamente a acur√°cia.

* **Escolha do K Ideal √© crucial** Valores muito pequenos ou muito altos de K podem prejudicar o desempenho.

### üéØ Principais Aplica√ß√µes
* **Detec√ß√£o de Anomalias**
* **Recomenda√ß√£o de Produtos**
* **Classifica√ß√£o de Doen√ßas**
* **Reconhecimento de Imagens**

<br>

## üå≤ Random Forest

### ‚öôÔ∏è Principais Caracter√≠sticas
A **Random Forest** √© um algoritmo de aprendizado baseado em um conjunto de √°rvores de decis√£o. Ele utiliza a t√©cnica de Bagging (Bootstrap Aggregating) para criar m√∫ltiplos subconjuntos aleat√≥rios dos dados de treinamento. Cada uma dessas √°rvores √© treinada com uma amostra diferente dos dados, selecionando aleatoriamente um subconjunto de vari√°veis.

### ‚úÖ Vantagens
* **Alta Precis√£o:** A combina√ß√£o de subconjuntos diferentes de dados desenvolve um modelo mais est√°vel.

* **Seguro contra Overfitting:** O modelo reduz o risco de Overfitting por utilizar m√∫ltiplas √°rvores e fazer uma "vota√ß√£o" dos resultados.

* **Lida com dados faltantes:** O modelo pode estimar os valores ausentes utilizando a m√©dia ponderada das observa√ß√µes ou utilizar √°rvores de decis√£o para preencher lacunas.

* **Indica a import√¢ncia das vari√°veis usadas na predi√ß√£o:** Consegue avaliar o impacto de cada vari√°vel e atribuir um peso de import√¢ncia.

### ‚ùå Desvantagens
* **Dificuldade de interpretar os resultados:** A decis√£o final vem da jun√ß√£o de muitas √°rvores.

* **Consome mais mem√≥ria:** O modelo precisa armazenar m√∫ltiplas √°rvores de decis√£o.

* **N√£o funciona bem com dados lineares:** Para problemas lineares, o modelo pode ser um exagero e at√© gerar previs√µes menos eficientes.

### üéØ Principais Aplica√ß√µes
* **Rela√ß√µes Banc√°rias**
* **Diagn√≥stico M√©dico**
* **Previs√£o no Mercado Financeiro**

<br>

## ‚ö° Support Vector Machine (SVM)

### ‚öôÔ∏è Principais Caracter√≠sticas
O **Support Vector Machine** √© um algoritmo que pode ser aplicado tanto para **Regress√£o** quanto para **Classifica√ß√£o**. O seu principal objetivo √© encontrar o melhor hiperplano que separa os dados, maximizando a dist√¢ncia entre os grupos diferentes em um espa√ßo N-dimensional.

### ‚úÖ Vantagens
* **Eficiente em espa√ßos de alta dimensionalidade:** O SVM mant√©m bom desempenho mesmo quando o conjunto de dados possui diversas *features*.

* **Eficiente com poucos dados:** O SVM foca apenas no pontos mais relevantes - chamados de **vetores de suporte** - para definir a fronteira de decis√£o.

* **Vers√°til:** Diferentes fun√ß√µes de Kernel podem ser aplicadas de acordo com o problema, permitindo que se adapte tanto a dados linearmente separ√°veis quanto a rela√ß√µes complexas.

### ‚ùå Desvantagens
* **N√£o √© t√£o escal√°vel:** O treinamento do modelo se torna cada vez mais dif√≠cil √† medida que o n√∫mero de amostras aumenta.

* **Sens√≠vel √† escolha do Kernel:** Uma configura√ß√£o inadequada do Kernel pode comprometer a capacidade de generaliza√ß√£o do modelo.

* **Dif√≠cil de interpretar Kernels n√£o lineares:** Quando utiliza fun√ß√µes complexas, como RBF ou Polinomial, o modelo se torna mais dif√≠cil de interpretar e entender como as decis√µes s√£o tomadas.

* **N√£o fornece probabilidade:** Por padr√£o, o modelo n√£o calcula a probabilidade das previs√µes apenas realiza uma classifica√ß√£o direta.

### üéØ Principais Aplica√ß√µes
* **Classifica√ß√£o de Texto**
* **Bioinform√°tica**
* **Classifica√ß√£o de Imagens**

<br>

## üìà Gradient Boosting

### ‚öôÔ∏è Principais Caracter√≠sticas
O **Gradient Boosting** √© um algoritmo de aprendizado baseado em √°rvores de decis√£o. Ele funciona construindo modelos de forma sequencial, onde cada novo modelo tenta corrigir os erros cometidos pelos anteriores. Esse processo √© guiado pelo gradiente do erro, que indica a dire√ß√£o de melhoria para minimizar a perda do modelo.

### ‚úÖ Vantagens
* **Alta Precis√£o:** Um dos algoritmos mais eficazes em tarefas estruturadas.

* **Modelo Flex√≠vel:** Pode ser usado para Classifica√ß√£o, Regress√£o e Ranking.

* **Import√¢ncia das Vari√°veis:** Permite visualizar quais vari√°veis t√™m mais influ√™ncia na decis√£o.

### ‚ùå Desvantagens
* **Tempo de Treinamento:** Tem um treinamento mais lento por construir modelos sequencialmente.

* **Sens√≠vel a Hiperpar√¢metros:** Requer ajuste cuidadoso do n√∫mero de √°rvores, profundidade e taxa de aprendizado para funcionar bem.

* **Menos Eficiente em Dados N√£o Estruturados:** N√£o √© ideal para imagens, √°udio ou texto puro.

### üéØ Principais Aplica√ß√µes
* **Problemas Tabulares em Geral**
* **Previs√£o de Risco de Cr√©dito**
* **Rotatividade de Clientes**

<br>

## üß† Rede Neural Artificial

### ‚öôÔ∏è Principais Caracter√≠sticas
A **Rede Neural Artificial** √© um algoritmo inspirado no funcionamento do c√©rebro humano. Ela simula a estrutura de neur√¥nios biol√≥gicos por meio de camadas interconectadas, nas quais os "neur√¥nios" artificiais s√£o ativados com base em pesos ajust√°veis. Durante o treinamento, esses pesos s√£o modificados iterativamente at√© que o modelo aprenda padr√µes e produza previs√µes com a menor margem de erro poss√≠vel.

### ‚úÖ Vantagens
* **Alto Poder de Modelagem:** Consegue aprender rela√ß√µes n√£o lineares complexas e at√© resolver problemas dif√≠ceis, como reconhecimento de imagem ou interpreta√ß√£o de linguagem natural.

* **Ajust√°vel a Diversos Cen√°rios:** Pode ser aplicado em tarefas de classifica√ß√£o, regress√£o, detec√ß√£o de anomalias, entre outras.

* **Capacidade de Autoajuste:** Utiliza algoritmos como o Backpropagation para ajustar seus par√¢metros automaticamente durante o treinamento.

### ‚ùå Desvantagens
* **Caixa-Preta:** √â dif√≠cil interpretar como a rede tomou determinada decis√£o, especialmente em redes profundas.

* **Treinamento Demorado:** Pode exigir muito tempo e poder computacional, especialmente com conjuntos grandes e redes profundas.

* **Risco de Overfitting:** Modelos muito grandes podem aprender os ru√≠dos do treino se n√£o forem bem regulados.

* **Necessidade de Dados em Grande Escala:** Desempenha melhor com grandes volumes de dados. Conjuntos pequenos podem limitar seu poder.

### üéØ Principais Aplica√ß√µes
* **Previs√£o de S√©ries Temporais**
* **Reconhecimento de Imagens**
* **Processamento de Linguagem Natural (NLP)**
* **Ve√≠culos Aut√¥nomos**

<br> 

## üîÅ LSTM (Long Short-Term Memory)

### ‚öôÔ∏è Principais Caracter√≠sticas
A **LSTM** √© um tipo de rede neural recorrente (RNN) projetada para aprender depend√™ncias temporais de longo prazo. Ela √© especialmente eficaz para dados sequenciais, pois consegue "lembrar" informa√ß√µes importantes por longos per√≠odos.

### ‚úÖ Vantagens
* **Mem√≥ria de Longo Prazo:** Consegue capturar padr√µes temporais que dependem de eventos passados distantes na sequ√™ncia.

* **Boa para S√©ries Temporais:** Ideal para prever valores futuros com base em sequ√™ncias hist√≥ricas, como clima e finan√ßas.

* **Pode Ser Combinada com Outras Camadas:** LSTM pode ser usada junto com camadas Dense, Dropout ou CNNs para tarefas mais robustas.

### ‚ùå Desvantagens
* **Treinamento Mais Lento:** Exige mais tempo e recursos computacionais que modelos tradicionais.

* **Mais Complexa de Ajustar:** Possui hiperpar√¢metros como n√∫mero de neur√¥nios, tamanho da janela e n√∫mero de camadas.

* **Dif√≠cil de Interpretar:** Apesar de mais transparente que outras redes profundas, ainda n√£o √© totalmente explic√°vel.

### üéØ Principais Aplica√ß√µes
* **Previs√£o de S√©ries Temporais**
* **Detec√ß√£o de Anomalias em Sequ√™ncias**
* **Modelagem de Linguagem Natural**

<br>

## üîó Refer√™ncias

### üìö Conceitos Gerais de Aprendizado Supervisionado
* [IBM - Supervised Learning](https://www.ibm.com/br-pt/topics/supervised-learning)
* [Deep Learning Book](https://www.deeplearningbook.com.br/)

---

### üìè Regress√£o Linear
* [IBM - Regress√£o Linear](https://www.ibm.com/br-pt/topics/linear-regression)

---

### üî¢ Regress√£o Log√≠stica
* [IBM - Regress√£o Log√≠stica](https://www.ibm.com/br-pt/topics/logistic-regression)
* [IBM Docs - SPSS Log√≠stica](https://www.ibm.com/docs/pt-br/spss-statistics/saas?topic=regression-logistic)
* [UCI - German Credit Data](https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data)

---

### üìç K-Nearest Neighbor (KNN)
* [IBM - KNN](https://www.ibm.com/think/topics/knn#:~:text=The%20k%2Dnearest%20neighbors%20(KNN)%20algorithm%20is%20a%20non,used%20in%20machine%20learning%20today.)
* [Kaggle - Iris Dataset](https://www.kaggle.com/datasets/uciml/iris)

---

### üå≤ Random Forest
* [Medium - Como funciona o Random Forest](https://medium.com/cinthiabpessanha/random-forest-como-funciona-um-dos-algoritmos-mais-populares-de-ml-cc1b8a58b3b4)
* [YouTube - How to Build a Random Forest Classification Model](https://www.youtube.com/watch?v=XnyYkxT_XgY)
* [EBAC - O que √© Random Forest ?](https://ebaconline.com.br/blog/random-forest-seo)
* [Kaggle - Titanic Dataset](https://www.kaggle.com/competitions/titanic/data)

---

### ‚ö° Support Vector Machine (SVM)
* [IBM - Support Vector Machine](https://www.ibm.com/br-pt/think/topics/support-vector-machine)
* [Scikit-learn - SVM](https://scikit-learn.org/stable/modules/svm.html)
* [Kaggle - Iris Dataset](https://www.kaggle.com/datasets/uciml/iris)

---

### üìà Gradient Boosting
* [Scikit-learn - Ensemble Methods](https://scikit-learn.org/stable/modules/ensemble.html#)
* [Scikit-learn - GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)
* [Google Developers - Introdu√ß√£o ao GBDT](https://developers.google.com/machine-learning/decision-forests/intro-to-gbdt?hl=pt-br)
* [UCI - Wine Dataset](https://archive.ics.uci.edu/dataset/109/wine)

---

### üß† Rede Neural Artificial
* [IBM - Redes Neurais](https://www.ibm.com/br-pt/think/topics/neural-networks)
* [Scikit-learn - Redes Neurais Supervisionadas](https://scikit-learn.org/stable/modules/neural_networks_supervised.html)
* [Kaggle - Heart Failure Prediction](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction)

---

### üîÅ LSTM (Long Short-Term Memory)
* [Wikip√©dia - Long Short-Term Memory (LSTM)](https://pt.wikipedia.org/wiki/Long_short-term_memory)
* [Did√°tica Tech - LSTM (Long Short-Term Memory)](https://didatica.tech/lstm-long-short-term-memory/)
* [Daily Minimum Temperatures Dataset (jbrownlee)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv)
